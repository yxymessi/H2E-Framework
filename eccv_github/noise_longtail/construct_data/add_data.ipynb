{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import tqdm\n",
    "PATH_IN_1 = \"./data/imagenet/ILSVRC/Data/CLS-LOC/train/\"\n",
    "PATH_IN_2 = \"./data/dataset/mini-imagenet/training/red_noise_nl_0.0\"\n",
    "PATH_OUT = \"./data/dataset/LT_with_noise/selected_imagenet/\"\n",
    "PATH_IMAGENET_NOISE = \"./data/dataset/LT_with_noise/imagenet_noise/\"\n",
    "PATH_NOISE = \"./data/dataset/mini-imagenet/all_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change the form of split  0.1\n",
    "\n",
    "noise_dict = {}\n",
    "\n",
    "with open ('./data/dataset/mini-imagenet/split/red_noise_nl_0.8.txt') as f:\n",
    "    word_list = f.readlines()\n",
    "\n",
    "for word in word_list:\n",
    "    temp_list = word.split()\n",
    "    if temp_list[1] not in noise_dict:\n",
    "        noise_dict[temp_list[1]] = []\n",
    "    if temp_list[0][0] != 'n':\n",
    "        noise_dict[temp_list[1]].append(temp_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct clean dataset and resize \n",
    "# 1000 pic per cls\n",
    "for cls in os.listdir(PATH_IN_2):\n",
    "    os.mkdir(os.path.join(PATH_OUT,cls))\n",
    "    temp_path = os.path.join(PATH_IN_2,cls)\n",
    "    # get cls id\n",
    "    selected_sample = os.listdir(temp_path)[0]\n",
    "    cls_id = selected_sample[:9]\n",
    "    choose_path = os.path.join(PATH_IN_1,cls_id)\n",
    "    name_list = os.listdir(choose_path)\n",
    "    random.shuffle(name_list)\n",
    "    selected_list = name_list[:1000]\n",
    "    for name in selected_list:\n",
    "        path_in = os.path.join(choose_path,name)\n",
    "        path_out = os.path.join(PATH_OUT,cls)\n",
    "        shutil.copy(path_in,path_out)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename and resize\n",
    "IMG_SIZE = 84\n",
    "for cls in os.listdir(PATH_OUT):\n",
    "    temp_path = os.path.join(PATH_OUT,cls)\n",
    "    for file_name in os.listdir(temp_path):\n",
    "        portion = os.path.splitext(file_name)\n",
    "        new_name = portion[0]+\".jpg\"\n",
    "        if portion[1] == \".JPEG\" :\n",
    "            os.rename(os.path.join(PATH_OUT,cls,file_name),os.path.join(PATH_OUT,cls,new_name))\n",
    "        img_array=cv2.imread(os.path.join(PATH_OUT,cls,new_name),cv2.IMREAD_COLOR)\n",
    "        new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "        save_path = os.path.join(PATH_OUT,cls,new_name)\n",
    "        cv2.imwrite(save_path,new_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct with-noise-dataset without long-tail\n",
    "# An example of 0.3 noise_ratio\n",
    "pic_len = 1000\n",
    "noise_rate_list = [0.3]\n",
    "for noise_rate in noise_rate_list:\n",
    "    sample_len = int(pic_len *(1-noise_rate))\n",
    "    noise_len = int(pic_len*noise_rate)\n",
    "    for key,value in noise_dict.items():\n",
    "        key = str(key)\n",
    "        if len(key) ==1:\n",
    "            key = '0'+key\n",
    "        os.mkdir(os.path.join(PATH_IMAGENET_NOISE,str(noise_rate),key))\n",
    "        random.shuffle(value)\n",
    "        # add noise\n",
    "        if len(value) > noise_len:\n",
    "            selected_noise_list = value[:noise_len]\n",
    "        else:\n",
    "            selected_noise_list = value[:len(value)]\n",
    "        \n",
    "        for selected_noise in selected_noise_list:\n",
    "            path_in = os.path.join(PATH_NOISE,selected_noise)\n",
    "            path_out = os.path.join(PATH_IMAGENET_NOISE,str(noise_rate),key)\n",
    "            shutil.copy(path_in,path_out)\n",
    "        # add sample\n",
    "        temp_path = os.path.join(PATH_OUT,key)\n",
    "        sample_list = os.listdir(temp_path)\n",
    "        random.shuffle(sample_list)\n",
    "        selected_sample_list = sample_list[:sample_len]\n",
    "        for selected_sample in selected_sample_list:\n",
    "            path_in = os.path.join(PATH_OUT,key,selected_sample)\n",
    "            path_out = os.path.join(PATH_IMAGENET_NOISE,str(noise_rate),key)\n",
    "            shutil.copy(path_in,path_out)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "406f4f9549b37ae82acfac2a427e8bacb16ad0662349a2733d23c3b8a370d9fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('LWN': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
